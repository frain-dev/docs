---
title: Sources
---

Sources are how events are ingested into Convoy. In this section, we explain the different types of sources and their use cases. Convoy currently supports three types of sources - REST API, HTTP Ingested and Message Brokers.

## REST API

This is an authenticated API to push events to a Convoy instance. It is designed specifically for an outgoing projects to push events to a specific endpoint. This source is only and automatically available for all outgoing projects.

## HTTP Ingestion

This is an unauthenticated API to receive webhook events from third-party webhook providers like Github, Shopify etc, It is designed for incoming projects to receive events from any provider. For each provider, a source needs to be configured with its necessary verification. Once configured, we provide you with a unique link to be supplied to the provider.

### Verification

Source verification can be configured in four different ways on Convoy:

-  **Hmac:** Hmac is a common mechanism most providers support for webhooks. Providers like [Shopify](https://www.shopify.com/), [Stripe](https://stripe.com/) etc. Creating a Hmac source looks like the below: <Frame>![create hmac source](/images/ingest-hmac.png)</Frame>

For HMAC verification mechanism, Convoy provides support for [simple and advanced signatures](https://getconvoy.io/docs/manual/signatures).

-  **Basic Authentication:** While not popular supported some providers user this mechanism to verify events. Creating a Basic Auth source looks like the below: <Frame>![create basic auth source](/images/ingest-basic.png)</Frame>
    
-  **API Keys:** Similar to Basic Authentication, API Keys while not popular are used by some providers to verify events. Providers like [Mono](https://mono.co/) <Frame>![create API key source](/images/ingest-api.png)</Frame>
    
-  **Custom Verification:** For some providers, like [Github](https://github.com/) and [Twitter](https://twitter.com/) the core verification mechanisms aren't sufficient. Though they are wrap around the core mechanisms, these modules have to be built specifically for eah provider.
    

Currently, we have support for [GitHub](https://github.com/), and have planned support for [Twitter](https://twitter.com/) and [Shopify](https://shopify.com/). You can request new sources by sending an email to `[[emailÂ protected]](https://getconvoy.io/cdn-cgi/l/email-protection)`.

## Message Brokers

Message Brokers provide extra reliability gains to ingest events from backend services to dispatch to client endpoints. With this, disparate services write events to a queue or topic, then convoy reads off the queue or topic and send the events to client endpoint. It is designed for and only available to outgoing projects.

### Google PubSub

To ingest events using Google PubSub, follow the steps outlined below:

-  **Create a PubSub Topic** <Frame>![create google pubsub topic](/images/google-pubsub.png)</Frame>
    
-  **Create a Subscription** <Frame>![create a subscription](/images/create-google-subscription.png)</Frame>
    
-  **Create a Service Account with PubSub Admin Role** <Frame>![create service account](/images/create-service-account.png)</Frame>
    
-  **Generate Service Account JSON Key** <Frame>![generate service account json key](/images/create-service-account-key.png)</Frame>
    
-  **Configure Source** Supply your `Project ID`, `Topic Name`, `Subscription` and upload your service account json key.
    
-  **Send Events** We write `JSON` events into the queue with the following format:
    
    
```json Sample Payload
{
   "endpoint_id": "01GTBP6SX313EZN6X3QE29CW6Z",
   "event_type": "compliance.completed",
   "custom_headers": {
      "X-Event-Key": "Event XYZ"
   },
   "data": {}
}
```

    
The payload is exactly the same as the one used with our REST API.
    

### Amazon SQS

To ingest events using Amazon SQS, follow the steps outlined below:

-  **Create an IAM User for authenticating with the SQS Queue and attach the AmazonSQSFullAccess policy to the user** <Frame>![create IAM user](/images/create-sqs-user.png)</Frame> <Frame>![attach AmazonSQSFullAccess policy](/images/attach-sqs-policy.png)</Frame>
    
-  **Under the security credentials tab for the IAM user, generate a new Access Key. Take note of the Access Key and Secret Key generated** <Frame>![generate a new access key](/images/generate-access-key.png)</Frame> <Frame>![create CLI access key](/images/cli-access-key.png)</Frame>
    
-  **Create a SQS Queue and specify the ARN of the IAM user under the access policy** <Frame>![create sqs queue](/images/create-sqs-queue.png)</Frame> <Frame>![add the IAM user under access policy](/images/access-policy-iam-user.png)</Frame>
    
-  **Configure Source** Supply your `Access Key`, `Secret Key`, `Queue Name` and `Default Region`.
    
-  **Send Events** We write `JSON` events into the queue with the following format:
    
    
    
```json Sample Payload
 {
   "endpoint_id": "01GTBP6SX313EZN6X3QE29CW6Z",
   "event_type": "compliance.completed",
   "custom_headers": {
      "X-Event-Key": "Event XYZ"
   },
   "data": {}
 }
```

### Kafka

The Kafka integration uses consumer groups for high availability and fault tolerance.

    
The payload is exactly the same as the one used with our REST API.