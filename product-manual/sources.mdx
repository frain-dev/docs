---
title: Sources
'og:title': Sources
'og:description': Sources are how events are ingested into Convoy. Convoy currently supports three types of sources - REST API, HTTP Ingested and Message Brokers such as Google PubSub, Amazon SQS and Kafka.
'twitter:description': Sources are how events are ingested into Convoy. Convoy currently supports three types of sources - REST API, HTTP Ingested and Message Brokers such as Google PubSub, Amazon SQS and Kafka.
'twitter:url': https://docs.getconvoy.io/product-manual/sources
---

Sources are how events are ingested into Convoy. In this section, we explain the different types of sources and their use cases. Convoy currently supports three types of sources:
- An authenticated REST API
- An unauthenticated ingest-API
- Message Brokers

## REST API

This is an authenticated API used to push events to a Convoy instance.
It is designed specifically for outgoing projects to send events to a specific endpoint,
a number of endpoints or all endpoints.
This source is only and automatically available for all outgoing projects.

```js payload structure
{
    "owner_id": "string, optional",
    "event_type": "string, required",
    "data": "object, required",
    "custom_headers": "object, optional",
    "idempotency_key": "string, optional",
    "endpoint_id": "string, depends"
}
```

- `owner_id`: Can be any arbitrary string, it is used to group endpoints together. We recommend setting it some internal id in your system
- `event_type`: The type of your event. e.g., `customer.created`, `customer.updated`.
- `data`: The data being sent.
- `custom_headers`: Any values included will be forwarded to the endpoints as HTTP header.
- `idempotency_key`: An identifier that is used to deduplicate events.
- `endpoint_id`: The id of the endpoint to send the event to.

```js sample payload
{
    "endpoint_id": "01HVNHCYTFW7MDKMQ43YFS20HZ",
    "owner_id": "01HVNHE3Z5EKKR9QZJVCH9XRWW",
    "event_type": "sample",
    "data": {},
    "custom_headers": {
        "x-sample-header": "sample-value"
    },
    "idempotency_key": "test123"
}
```

## HTTP Ingestion

This is an unauthenticated API to receive webhook events from third-party webhook providers like GitHub, Shopify etc.,
It is designed for incoming projects to receive events from any provider.
For each provider, a source needs to be configured with its necessary verification.
Once configured, we provide you with a unique link to be supplied to the provider.

### Verification

Source verification can be configured in four different ways on Convoy:

-  **Hmac:** Hmac is a common mechanism most providers support for webhooks. Providers like [Shopify](https://www.shopify.com/), [Stripe](https://stripe.com/) etc. Creating a Hmac source looks like the below: <Frame>![create hmac source](/images/ingest-hmac.png)</Frame>

For HMAC verification mechanism, Convoy provides support for [simple and advanced signatures](https://getconvoy.io/docs/manual/signatures).

-  **Basic Authentication:** While not popular supported some providers user this mechanism to verify events. Creating a Basic Auth source looks like the below: <Frame>![create basic auth source](/images/ingest-basic.png)</Frame>
    
-  **API Keys:** Similar to Basic Authentication, API Keys while not popular are used by some providers to verify events. Providers like [Mono](https://mono.co/) <Frame>![create API key source](/images/ingest-api.png)</Frame>
    
-  **Custom Verification:** For some providers, like [Github](https://github.com/) and [Twitter](https://twitter.com/) the core verification mechanisms aren't sufficient. Though they are wrap around the core mechanisms, these modules have to be built specifically for eah provider.
    

Currently, we have support for [GitHub](https://github.com/), and have planned support for [Twitter](https://twitter.com/) and [Shopify](https://shopify.com/). You can request new sources by sending an email to `[[emailÂ protected]](https://getconvoy.io/cdn-cgi/l/email-protection)`.

## Message Brokers

Message Brokers provide extra reliability gains to ingest events from backend services to dispatch to client endpoints. With this, disparate services write events to a queue or topic, then convoy reads off the queue or topic and send the events to client endpoint. It is designed for and only available to outgoing projects.

### Google PubSub

To ingest events using Google PubSub, follow the steps outlined below:

-  **Create a PubSub Topic** <Frame>![create google pubsub topic](/images/google-pubsub.png)</Frame>
    
-  **Create a Subscription** <Frame>![create a subscription](/images/create-google-subscription.png)</Frame>
    
-  **Create a Service Account with PubSub Admin Role** <Frame>![create service account](/images/create-service-account.png)</Frame>
    
-  **Generate Service Account JSON Key** <Frame>![generate service account json key](/images/create-service-account-key.png)</Frame>
    
-  **Configure Source** Supply your `Project ID`, `Topic Name`, `Subscription` and upload your service account json key.
    
-  **Send Events** We write `JSON` events into the queue with the following format:
    
    
```json Sample Payload
{
   "endpoint_id": "01GTBP6SX313EZN6X3QE29CW6Z",
   "event_type": "compliance.completed",
   "custom_headers": {
      "X-Event-Key": "Event XYZ"
   },
   "data": {}
}
```

    
The payload is exactly the same as the one used with our REST API.
    

### Amazon SQS

To ingest events using Amazon SQS, follow the steps outlined below:

-  **Create an IAM User for authenticating with the SQS Queue and attach the AmazonSQSFullAccess policy to the user** <Frame>![create IAM user](/images/create-sqs-user.png)</Frame> <Frame>![attach AmazonSQSFullAccess policy](/images/attach-sqs-policy.png)</Frame>
    
-  **Under the security credentials tab for the IAM user, generate a new Access Key. Take note of the Access Key and Secret Key generated** <Frame>![generate a new access key](/images/generate-access-key.png)</Frame> <Frame>![create CLI access key](/images/cli-access-key.png)</Frame>
    
-  **Create a SQS Queue and specify the ARN of the IAM user under the access policy** <Frame>![create sqs queue](/images/create-sqs-queue.png)</Frame> <Frame>![add the IAM user under access policy](/images/access-policy-iam-user.png)</Frame>
    
-  **Configure Source** Supply your `Access Key`, `Secret Key`, `Queue Name` and `Default Region`.
    
-  **Send Events** We write `JSON` events into the queue with the following format:
    
    
    
```json Sample Payload
 {
   "endpoint_id": "01GTBP6SX313EZN6X3QE29CW6Z",
   "event_type": "compliance.completed",
   "custom_headers": {
      "X-Event-Key": "Event XYZ"
   },
   "data": {}
 }
```

### Kafka

The Kafka integration reads a messages off a topic using a consumer group for high availability and fault tolerance.
> The number of partitions for the topic should match the number of workers.